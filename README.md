# Предсказание CTR для постов ВКонтакте

## Описание проекта

Этот проект направлен на разработку модели для предсказания Click-Through Rate (CTR) постов в социальной сети ВКонтакте. CTR определяется как вероятность конверсии просмотра поста в различные активности, такие как лайки, комментарии, репосты и пересылки в личные сообщения. В проекте используются как текстовые, так и визуальные данные постов, а также числовые признаки. Для объединения предсказаний базовых моделей применяется CatBoost в качестве мета-модели.

## Содержание

- [Описание проекта](#описание-проекта)
- [Содержание](#содержание)
- [Технологии](#технологии)
- [Структура проекта](#структура-проекта)
- [Гипотезы и эксперименты](#гипотезы-и-эксперименты)
  - [Формирование таргета](#формирование-таргета)
  - [Гипотеза 1: Обучение CatBoost с множеством эмбеддингов](#гипотеза-1-обучение-catboost-с-множеством-эмбеддингов)
  - [Гипотеза 2: Обучение мультимодальных моделей](#гипотеза-2-обучение-мультимодальных-моделей)
    - [2.1 BERT](#21-bert)
    - [2.2 CLIP](#22-clip)
    - [2.3 LXMERT](#23-lxmert)
    - [2.4 ViLBERT](#24-vilbert)
  - [Гипотеза 3: Переход к бинарной классификации](#гипотеза-3-переход-к-бинарной-классификации)
- [Установка](#установка)
- [Заключение](#заключение)

## Технологии

- Python
- Pandas
- NumPy
- Scikit-learn
- CatBoost
- PyTorch
- Hugging Face Transformers
- Pillow

## Структура проекта

```
VKLAB/
├── notebooks/
│   └── EDA.ipynb
├── data/
│   ├── dataset.csv
│   ├── embeddings/
│   │   ├── bert_embeddings.npy
│   │   ├── resnet_embeddings.npy
│   │   └── img2text_embeddings.npy
│   ├── processed_data.pkl
│   ├── X_train.npy
│   ├── X_test.npy
│   ├── y_train.npy
│   └── y_test.npy
├── models/
│   └── catboost_model.cbm
├── logs/
│   └── wandb/
├── src/
│   ├── data_loader.py
│   ├── feature_extractor.py
│   ├── model.py
│   ├── trainer.py
│   └── utils.py
├── requirements.txt
├── README.md
└── .gitignore
```

* data/: Содержит исходный датасет.
* notebooks/: Jupyter Notebook для первичного разведывательного анализа (EDA).
* src/: Исходный код проекта.
    * data_preprocessing.py: Скрипты для предобработки данных.
    * models.py: Определение архитектур моделей.
    * train_text_model.py: Скрипт для обучения текстовой модели.
    * train_image_model.py: Скрипт для обучения визуальной модели.
    * train_catboost.py: Скрипт для обучения мета-модели CatBoost.
    * utils.py: Вспомогательные функции.
* requirements.txt: Список зависимостей проекта.
* README.md: Описание проекта.
* .gitignore: Файлы и папки, игнорируемые Git.

## Гипотезы и эксперименты

### Формирование таргета

Таргет был сформирован как отношение `engagement/view`, где `engagement` — это любая активность пользователя (лайки, комментарии, репосты и т.д.), а `view` — количество просмотров поста.

### Гипотеза 1: Обучение CatBoost с множеством эмбеддингов

**Описание:**

В качестве признаков использовались различные эмбеддинги, полученные из моделей BERT, CLIP, TF-IDF, ResNet. Целью было проверить, сможет ли модель CatBoost эффективно объединить различные типы эмбеддингов для предсказания CTR. Далее можно предсказывать каждую из конверсий и из них уже оценивать engagement.

**Результаты:**

- **MSE:** 0.0091
- **RMSE:** 0.0953
- **R² Score:** 0.3282

### Гипотеза 2: Обучение мультимодальных моделей

**Описание:**

Проверка эффективности мультимодальных моделей, способных одновременно обрабатывать текстовую и визуальную информацию.

#### 2.1 BERT

**Результаты:**

- **Mean Squared Error:** 0.0102
- **R-squared:** 0.2429

#### 2.2 CLIP

**Результаты:**

- **Mean Squared Error:** 0.0113
- **R-squared:** 0.1601

#### 2.3 LXMERT

**Результаты:**

- **MSE:** 0.0128
- **MAE:** 0.0769
- **R²:** 0.0498

#### 2.4 ViLBERT

**Результаты:**

*(Здесь можно добавить результаты для ViLBERT, если они доступны.)*

**Вывод по гипотезе 2:**

Модель CatBoost с использованием различных эмбеддингов показала лучшие результаты по сравнению с отдельными мультимодальными моделями. Это может указывать на то, что комбинирование признаков и использование градиентного бустинга эффективно для данной задачи.

### Гипотеза 3: Переход к бинарной классификации

**Описание:**

Попытка улучшить качество моделей путем преобразования задачи из регрессии в классификацию. Для этого таргет был разбит на бинарный признак, где 1 означает активность (если показатель выше определенного порога), а 0 — ее отсутствие.

**Проблема:**

Сильный дисбаланс классов: около 94% примеров относятся к классу 0 и только 6% к классу 1. Это отрицательно сказалось на качестве моделей, так как они склонны предсказывать преобладающий класс.

**Результаты:**

#### CLIP

- **Accuracy:** 0.2272
- **Precision:** 0.0691
- **Recall:** 0.9085
- **F1-Score:** 0.1284
- **ROC AUC:** 0.5450

#### LXMERT

- **Валидация:**
  - **Потеря:** 0.6158
  - **Точность:** 0.7796
- **Метрики:**
  - **Precision:** 0.0676
  - **Recall:** 0.1966
  - **F1:** 0.1006
  - **ROC AUC:** 0.5154

**Вывод по гипотезе 3:**

Переход к классификации не улучшил качество предсказаний из-за сильного дисбаланса классов. Модели демонстрируют низкие значения Precision и Recall для меньшего класса, что свидетельствует о неспособности модели правильно идентифицировать активные посты.

## Установка

1. Клонируйте репозиторий:

   ```bash
   git clone https://github.com/torchme/vklab.git
   ```

2. Установите зависимости:

   ```bash
   pip install -r requirements.txt
   ```

## Заключение
Проведенные эксперименты показали, что:

* CatBoost с различными эмбеддингами демонстрирует наилучшие результаты по метрикам MSE и R², что указывает на эффективность комбинирования признаков из разных моделей.

* Мультимодальные модели (BERT, CLIP, LXMERT) уступают CatBoost по качеству предсказаний в данной задаче. Возможно, это связано с ограниченностью данных или недостаточной адаптацией моделей к специфике задачи.

* Преобразование задачи в классификацию не привело к улучшению результатов из-за сильного дисбаланса классов. Для решения этой проблемы необходимо применять методы балансировки данных, такие как oversampling меньшего класса или использование специализированных метрик и алгоритмов, устойчивых к дисбалансу.

## Рекомендации для дальнейшей работы:

* Улучшение обработки визуальных признаков: Использовать более продвинутые методы для извлечения признаков из изображений или дообучить модели на специфичных для задачи данных.

* Обработка дисбаланса классов: Применить техники балансировки, такие как SMOTE, или использовать методы обучения с учетом дисбаланса, например, взвешенные функции потерь.

* Анализ данных: Провести более глубокий анализ данных, чтобы выявить дополнительные закономерности и особенности, которые могут быть учтены в модели.

* Эксперименты с другими моделями: Попробовать другие архитектуры мультимодальных моделей или методы ансамблирования.
